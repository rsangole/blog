---
title: Finite Mixture Modeling using Flexmix
author: Rahul Sangole
date: '2017-02-01'
slug: finite-mixture-modeling-using-flexmix
categories:
  - R
tags:
  - R
  - flexmix
  - mixture modeling
output:
  blogdown::html_page:
    toc: true
---


<div id="TOC">
<ul>
<li><a href="#model-based-clustering">Model Based Clustering</a><ul>
<li><a href="#quick-eda">Quick EDA</a></li>
<li><a href="#model-building">Model building</a></li>
</ul></li>
<li><a href="#mixtures-of-regressions">Mixtures of Regressions</a><ul>
<li><a href="#quick-eda-1">Quick EDA</a></li>
<li><a href="#model-building-1">Model Building</a></li>
<li><a href="#results">Results</a></li>
<li><a href="#further-investigation">Further investigation</a></li>
</ul></li>
<li><a href="#notes">Notes</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<p>This page replicates the codes written by Grun &amp; Leish (2007) in <a href="http://ro.uow.edu.au/cgi/viewcontent.cgi?article=3410&amp;context=commpapers">‘FlexMix: An R package for finite mixture modelling’, University of Wollongong, Australia.</a> My intent here was to learn the flexmix package by replicating the results by the authors.</p>
<div id="model-based-clustering" class="section level1">
<h1>Model Based Clustering</h1>
<p>The model based clustering on the whiskey dataset. The whiskey dataset is from the Simmons Study of Media and Markets (Fall 1997), and contains the incidence matrix for scotch brands in households who reported consuming scotch for period of 1 year. The dataset is taken from <a href="https://www.researchgate.net/profile/Greg_Allenby/publication/247837327_Multivariate_Analysis_of_Multiple_Response_Data/links/547480910cf2778985abe334.pdf">Edwards and Allenby (2003).</a></p>
<p>Load the necessary packges first: <code>tidyverse</code> and <code>flexmix</code>.</p>
<pre class="r"><code>library(tidyverse)
library(flexmix)</code></pre>
<div id="quick-eda" class="section level2">
<h2>Quick EDA</h2>
<p>Quick look at the data itself. The dataframe consists of 2 elements - frequency (numeric vector), and the incidence matrix. There are total of 484 observations.</p>
<pre class="r"><code>data(&quot;whiskey&quot;)
df &lt;- whiskey
set.seed(1802)
str(df)</code></pre>
<pre><code>## &#39;data.frame&#39;:    484 obs. of  2 variables:
##  $ Freq     : int  1 1 10 14 10 23 9 8 1 12 ...
##  $ Incidence: num [1:484, 1:21] 1 0 0 0 0 0 0 0 0 0 ...
##   ..- attr(*, &quot;dimnames&quot;)=List of 2
##   .. ..$ : chr  &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...
##   .. ..$ : chr  &quot;Singleton&quot; &quot;Knockando&quot; &quot;White Horse&quot; &quot;Scoresby Rare&quot; ...</code></pre>
<p>The column names of the <code>df$Incidence</code> matrix are the brands of whiskey.</p>
<pre class="r"><code>colnames(df$Incidence)</code></pre>
<pre><code>##  [1] &quot;Singleton&quot;                  &quot;Knockando&quot;                 
##  [3] &quot;White Horse&quot;                &quot;Scoresby Rare&quot;             
##  [5] &quot;Ushers&quot;                     &quot;Macallan&quot;                  
##  [7] &quot;Grant&#39;s&quot;                    &quot;Passport&quot;                  
##  [9] &quot;Black &amp; White&quot;              &quot;Clan MacGregor&quot;            
## [11] &quot;Ballantine&quot;                 &quot;Pinch (Haig)&quot;              
## [13] &quot;Other brands&quot;               &quot;Cutty Sark&quot;                
## [15] &quot;Glenfiddich&quot;                &quot;Glenlivet&quot;                 
## [17] &quot;J&amp;B&quot;                        &quot;Dewar&#39;s White Label&quot;       
## [19] &quot;Johnnie Walker Black Label&quot; &quot;Johnnie Walker Red Label&quot;  
## [21] &quot;Chivas Regal&quot;</code></pre>
<p>The incidence matrix shows a relationship between two classes of variables - in this case: freqencies of the brand of whiskey in the past year, and the brand of whiskey itself. Quick look at a portion of the matrix:</p>
<pre class="r"><code>df$Incidence[sample(x = 1:484,size = 10),sample(1:21,3)]</code></pre>
<pre><code>##     Ballantine Johnnie Walker Red Label White Horse
## 304          1                        1           0
## 404          0                        0           0
## 465          0                        1           0
## 349          0                        0           0
## 19           0                        0           0
## 331          0                        1           0
## 370          0                        1           0
## 367          0                        1           0
## 82           0                        1           0
## 384          1                        1           0</code></pre>
<p>The popularity of the whiskeys can be seen here. Chivas Regal seems to be a favourite, which puts my personal preference in line with a larger population :)</p>
<pre class="r"><code>c &lt;- colSums(df$Incidence)
d1 &lt;- data.frame(Brand=names(c),counts=c,row.names = NULL)
d1 &lt;- d1 %&gt;% left_join(whiskey_brands) %&gt;% arrange(-counts)
ggplot(d1,aes(reorder(Brand,counts),counts,fill=Type))+geom_bar(stat=&#39;identity&#39;)+coord_flip()+labs(y=&#39;Counts&#39;,x=&#39;Whiskey Brand&#39;)</code></pre>
<p><img src="/post/2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
<div id="model-building" class="section level2">
<h2>Model building</h2>
<p>The first model in the paper is a stepped Flexmix model, specific for binary variables using the <code>FLXMcvbinary()</code> model. Since the objective is to cluster the model based on the Incidence counts and Frequencies, the formula used is <code>Incidence ~ 1</code>. The frequencies themselves are input as <code>weights</code> in the formula.</p>
<pre class="r"><code>wh_mix &lt;- stepFlexmix(Incidence ~ 1,
                      weights = ~ Freq, 
                      data = df,
                      model = FLXMCmvbinary(truncated = TRUE),
                      control = list(minprior = 0.005),
                      k=1:7,
                      nrep=5)</code></pre>
<pre><code>## 1 : * * * * *
## 2 : * * * * *
## 3 : * * * * *
## 4 : * * * * *
## 5 : * * * * *
## 6 : * * * * *
## 7 : * * * * *</code></pre>
<pre class="r"><code>summary(wh_mix)</code></pre>
<pre><code>##      Length       Class        Mode 
##           1 stepFlexmix          S4</code></pre>
<p>A top model can be selecting using BIC or AIC criteria. The BIC criteria selects a model with 5 clusters.</p>
<pre class="r"><code>plot(BIC(wh_mix),type=&#39;b&#39;,ylab=&#39;BIC&#39;)
points(x = which.min(BIC(wh_mix)),min(BIC(wh_mix)),col=&#39;red&#39;,pch=20)</code></pre>
<p><img src="/post/2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>wh_best &lt;- getModel(wh_mix,&#39;BIC&#39;)
print(wh_best)</code></pre>
<pre><code>## 
## Call:
## stepFlexmix(Incidence ~ 1, weights = ~Freq, data = df, model = FLXMCmvbinary(truncated = TRUE), 
##     control = list(minprior = 0.005), k = 5, nrep = 5)
## 
## Cluster sizes:
##   1   2   3   4   5 
## 804 941 163 286  24 
## 
## convergence after 73 iterations</code></pre>
<p>The proportions of the observations in each cluster are shown here:</p>
<pre class="r"><code>round(prop.table(table(wh_best@cluster)),2)</code></pre>
<pre><code>## 
##    1    2    3    4    5 
## 0.19 0.27 0.23 0.26 0.04</code></pre>
<p>The parameter estimates plotted for model with k=5 is shown below graphically. Component 3 (4% of households) contain the largest number of different brands. Component 1 (25% of households) seen to prefer single malt whiskeys. Component 4 (23% of households) are across the board with Brands, but perhaps show lesser of an interest in single malts, just like Component 5 (29% of the households).</p>
<pre class="r"><code># wh_best.prior &lt;- prior(wh_best)
wh_best.param &lt;- parameters(wh_best)
wh_best.param &lt;- data.frame(Brand=stringr::str_replace(rownames(wh_best.param),pattern = &#39;center.&#39;,replacement = &#39;&#39;),
wh_best.param,row.names = NULL) 
wh_best.param &lt;- wh_best.param %&gt;% gather(Components,Value,Comp.1:Comp.5)
wh_best.param &lt;- wh_best.param %&gt;% left_join(y = whiskey_brands,by = &#39;Brand&#39;)
ggplot(wh_best.param,aes(y=Value,x=Brand,fill=Type))+
    geom_bar(stat=&#39;identity&#39;)+
    coord_flip()+
    facet_grid(.~Components)</code></pre>
<p><img src="/post/2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-9-1.png" width="768" /></p>
</div>
</div>
<div id="mixtures-of-regressions" class="section level1">
<h1>Mixtures of Regressions</h1>
<p>The next example in the paper is the patent data in Wang et al. (1998). The help file <code>?patent</code> notes that the data consists of the number of patents, R&amp;D spending and sales in millions of dollar for 70 pharmaceutical and biomedical companies in 1976, taken from the National Bureau of Economic Research R&amp;D Masterfile.</p>
<div id="quick-eda-1" class="section level2">
<h2>Quick EDA</h2>
<p>The dependant variable here is <code>Patents</code>. Independant variable is <code>lgRD</code> which is the log of R&amp;D spending. The objective in this exercise is to try and find how many may clusters exist within this bi-variate dataset. When I started this exercise, it seemed quite moot to me, since visually, I couldn’t really tell any distict clusters. But, the results show otherwise.</p>
<pre class="r"><code>data(&quot;patent&quot;)
df_patent &lt;- tbl_df(patent)
df_patent</code></pre>
<pre><code>## # A tibble: 70 x 4
##                                     Company Patents    RDS    lgRD
##  *                                    &lt;chr&gt;   &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;
##  1 ABBOTT LABORATORIES                           42 0.0549  4.0869
##  2 AFFILIATED HOSPITAL PRDS                       1 0.0032 -2.0794
##  3 ALBERTO-CULVER CO                              3 0.0078  0.1187
##  4 ALCON LABORATORIES                             2 0.0803  1.8796
##  5 ALLERGAN PHARMACEUTICALS INC                   3 0.0686  1.1033
##  6 ALZA CORP-CL A                                40 3.3319  2.0794
##  7 AMERICAN HOME PRODUCTS CORP                   60 0.0243  4.0953
##  8 AMERICAN HOSPITAL SUPPLY                      30 0.0128  2.8333
##  9 AMERICAN STERILIZER CO                         7 0.0252  1.3915
## 10 AVON PRODUCTS                                  3 0.0094  2.6048
## # ... with 60 more rows</code></pre>
<pre class="r"><code>plot(Patents~lgRD,df_patent)</code></pre>
<p><img src="/post/2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
<div id="model-building-1" class="section level2">
<h2>Model Building</h2>
<p>The paper mentions that Wang et al. (1998) chose a finite mixture of three Poisson regression models to represent the data. The <code>FLXMRglm()</code> is used for the Poisson model with a concomitant variable modeled using <code>FLXPmultinom()</code>.</p>
<pre class="r"><code>pat_mix &lt;- flexmix(Patents ~ lgRD, k = 3, data = df_patent, model = FLXMRglm(family = &quot;poisson&quot;), concomitant = FLXPmultinom(~RDS))
pat_mix</code></pre>
<pre><code>## 
## Call:
## flexmix(formula = Patents ~ lgRD, data = df_patent, k = 3, 
##     model = FLXMRglm(family = &quot;poisson&quot;), concomitant = FLXPmultinom(~RDS))
## 
## Cluster sizes:
##  1  2  3 
## 37 25  8 
## 
## convergence after 21 iterations</code></pre>
<p>The clusters obtained from the analysis are given by a <code>cluster()</code> function.</p>
<pre class="r"><code>clusters(pat_mix)</code></pre>
<pre><code>##  [1] 2 1 1 2 1 3 2 1 1 2 1 1 1 1 2 2 2 1 1 2 2 2 3 1 1 1 1 1 1 2 1 1 1 2 3
## [36] 1 2 2 3 2 1 1 2 1 2 1 1 1 3 1 1 2 1 2 1 1 1 2 2 2 1 2 1 1 3 3 1 2 3 2</code></pre>
</div>
<div id="results" class="section level2">
<h2>Results</h2>
<p>The data is replotted but with colors for the clusters and additional splines. As we can see, the model beautifully models three lines through three clusters in the data.</p>
<pre class="r"><code>Components &lt;- factor(clusters(pat_mix))
xyplot(Patents~lgRD,groups = Components,df_patent,type=c(&#39;p&#39;,&#39;spline&#39;))</code></pre>
<p><img src="/post/2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
</div>
<div id="further-investigation" class="section level2">
<h2>Further investigation</h2>
<p>The <code>flexmix</code> package has a function to plot rootograms of the posterior probabilities of observations. Observations where the a-posteriori probability is large for component #1 and #3 are indicated. As we can see where component #1 has highest probabilities indicated in the 1st bucket, they are lowest in #2 and #3 buckets.</p>
<pre class="r"><code>plot(pat_mix,mark=1)</code></pre>
<p><img src="/post/2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<pre class="r"><code>plot(pat_mix,mark=3)</code></pre>
<p><img src="/post/2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-14-2.png" width="672" /></p>
<p>A summary of the mixture model results show the estimated priors, number of observations within each cluster (size), number of observations with p&gt;10^-4 (post&gt;0), and a ratio of the two. The rations of 0.58, 0.42 and 0.18 indicate big overlaps of the clusters. This can also be observed by the large portion of values in the mid-section of the rootogram above.</p>
<pre class="r"><code>summary(pat_mix)</code></pre>
<pre><code>## 
## Call:
## flexmix(formula = Patents ~ lgRD, data = df_patent, k = 3, 
##     model = FLXMRglm(family = &quot;poisson&quot;), concomitant = FLXPmultinom(~RDS))
## 
##        prior size post&gt;0 ratio
## Comp.1 0.497   37     63 0.587
## Comp.2 0.380   25     60 0.417
## Comp.3 0.124    8     45 0.178
## 
## &#39;log Lik.&#39; -202.7633 (df=10)
## AIC: 425.5265   BIC: 448.0115</code></pre>
<p>Tests of significance of the coefficients are obtained by the <code>refit()</code>. In each cluster the intercept and lgRD are both statistically significant at the 0.05 level. The black bars in the plot are 95% CI over the point estimates.</p>
<pre class="r"><code>rm &lt;- refit(pat_mix)
summary(rm)</code></pre>
<pre><code>## $Comp.1
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  0.64189    0.28348  2.2643  0.02355 *  
## lgRD         0.92618    0.06562 14.1143  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## $Comp.2
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -1.32675    0.52622 -2.5213  0.01169 *  
## lgRD         1.29118    0.12463 10.3601  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## $Comp.3
##             Estimate Std. Error z value  Pr(&gt;|z|)    
## (Intercept)  1.95769    0.41935  4.6684 3.036e-06 ***
## lgRD         0.70556    0.12009  5.8754 4.217e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>plot(rm,bycluster=F)</code></pre>
<p><img src="/post/2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>The authors note that “estimates vary between all components even though the co- efficients for lgRD are similar for the first and third component”.</p>
</div>
</div>
<div id="notes" class="section level1">
<h1>Notes</h1>
<ul>
<li>For both the models, although I’m using the exact datasets and seed values, I observe different values for proportions in each cluster (for model #1) as well as P values for significance etc (for model #2). This could be due to some changes in the underlying flexmix codes since 2007.</li>
</ul>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<ul>
<li><a href="http://ro.uow.edu.au/cgi/viewcontent.cgi?article=3410&amp;context=commpapers" class="uri">http://ro.uow.edu.au/cgi/viewcontent.cgi?article=3410&amp;context=commpapers</a></li>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.491.3320&amp;rep=rep1&amp;type=pdf" class="uri">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.491.3320&amp;rep=rep1&amp;type=pdf</a></li>
<li><a href="https://cran.r-project.org/web/packages/flexmix/index.html" class="uri">https://cran.r-project.org/web/packages/flexmix/index.html</a></li>
<li><a href="https://cran.r-project.org/web/packages/flexmix/vignettes/mixture-regressions.pdf" class="uri">https://cran.r-project.org/web/packages/flexmix/vignettes/mixture-regressions.pdf</a></li>
<li><a href="https://cran.r-project.org/web/packages/flexmix/vignettes/flexmix-intro.pdf" class="uri">https://cran.r-project.org/web/packages/flexmix/vignettes/flexmix-intro.pdf</a></li>
<li><a href="https://cran.r-project.org/web/packages/flexmix/vignettes/bootstrapping.pdf" class="uri">https://cran.r-project.org/web/packages/flexmix/vignettes/bootstrapping.pdf</a></li>
<li><a href="https://www.researchgate.net/profile/Greg_Allenby/publication/247837327_Multivariate_Analysis_of_Multiple_Response_Data/links/547480910cf2778985abe334.pdf">https://www.researchgate.net/profile/Greg_Allenby/…/…e334.pdf</a></li>
</ul>
</div>
