{
  "hash": "9316fb96506f77473036a5d823d4a9a7",
  "result": {
    "markdown": "---\ntitle: Performance Benchmarking for Dummy Variable Creation\nauthor: Rahul\ndate: '2017-09-27'\nslug: dummy-variables-one-hot-encoding\ncategories:\n  - R\ntags:\n  - R\n  - dummy variables\n  - benchmarking\n  - programming-practices\noutput:\n  blogdown::html_page:\n    toc: true\n---\n\n\n\n## Motivation\n\nVery recently, at work, we got into a discussion about creation of dummy variables in R code. We were dealing with a fairly large dataset of roughly 500,000 observations for roughly 120 predictor variables. Almost all of them were categorical variables, many of them with a fairly large number of factor levels (think 20-100). The types of models we needed to investigate required creation of dummy variables (think [xgboost](http://xgboost.readthedocs.io)). There are a few ways to convert categoricals into dummy variables in R. However, I did not find any comparison of performance for large datasets.\n\nSo here it goes.\n\n## Why do we need dummy variables?\n\nI won't say any more here. Plenty of good resources on the web: [here](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqwhat-is-dummy-coding/), [here](http://www.sjsu.edu/people/edward.cohen/courses/c2/s1/Week_14_dummy_variable_slides.pdf), and  [here](http://www.polsci.ucsb.edu/faculty/glasgow/ps15/ps15lect15.pdf).\n\n## Ways to create dummy variables in R\n\nThese are the methods I've found to create dummy variables in R. I've explored each of these \n\n* stats::model.matrix()\n* dummies::dummy.data.frame() \n* dummy::dummy()  \n* caret::dummyVars()\n\nPrepping some data to try these out. Using the `HairEyeColor` dataset as an example. It consists of 3 categorical vars and 1 numerical var. Perfect to try things out. Adding a response variable `Y` too.\n\n\n::: {.cell hash='2017-09-26-dummy-variables-one-hot-encoding_cache/html/unnamed-chunk-1_18467bb0bb61953fb398bde9202dd4a9'}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(readr)\nlibrary(purrr)\nlibrary(magrittr)\ndata(\"HairEyeColor\")\nHairEyeColor %<>% tbl_df()\nHairEyeColor$Y = sample(c(0,1),dim(HairEyeColor)[1],replace = T) %>% factor(levels = c(0,1),labels = c('No','Yes'))\nglimpse(HairEyeColor)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 32\nColumns: 5\n$ Hair <chr> \"Black\", \"Brown\", \"Red\", \"Blond\", \"Black\", \"Brown\", \"Red\", \"Blond…\n$ Eye  <chr> \"Brown\", \"Brown\", \"Brown\", \"Brown\", \"Blue\", \"Blue\", \"Blue\", \"Blue…\n$ Sex  <chr> \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"…\n$ n    <dbl> 32, 53, 10, 3, 11, 50, 10, 30, 10, 25, 7, 5, 3, 15, 7, 8, 36, 66,…\n$ Y    <fct> Yes, Yes, Yes, No, Yes, No, Yes, No, Yes, No, No, Yes, No, No, Ye…\n```\n:::\n:::\n\n\nLet's look at each package:\n\n### `stats` package\n\nThe `stats` package has a function called `model.matrix` which converts factor variables to dummy variables. It also drops the response variable.\n\n\n*Some pros*\n\n+ Works with tibbles\n+ Really fast\n+ Retains numerical columns as is\n+ Formula interface allows one to specify what `Y` is\n\n*Some cons*\n\n+ Need to add the response `Y` back into the mix, if we need it\n\n\n::: {.cell hash='2017-09-26-dummy-variables-one-hot-encoding_cache/html/unnamed-chunk-2_b1dfbab2b616f219a2e500b5660769dc'}\n\n```{.r .cell-code}\nhead(model.matrix(Y~.-1,HairEyeColor),3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  HairBlack HairBlond HairBrown HairRed EyeBrown EyeGreen EyeHazel SexMale  n\n1         1         0         0       0        1        0        0       1 32\n2         0         0         1       0        1        0        0       1 53\n3         0         0         0       1        1        0        0       1 10\n```\n:::\n:::\n\n\n### `dummies` package\n\n`dummies` has a command called `dummy.data.frame` which does the needful.\n\n    \n*Some pros*\n\n+ Retains numerical columns as is\n+ Can create based dummy variables for numeric columns too\n\n*Some cons*\n\n+ Doesn't work with tibbles\n+ Doesn't have a formula interface to specify what `Y` is. Need to manually remove response variable from dataframe\n\n\n::: {.cell hash='2017-09-26-dummy-variables-one-hot-encoding_cache/html/unnamed-chunk-3_a02c6f327abf6977b6fba089d3310a2d'}\n\n```{.r .cell-code}\nlibrary(dummies)\nhead(dummy.data.frame(data = as.data.frame(HairEyeColor),sep=\".\"),3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Hair.Black Hair.Blond Hair.Brown Hair.Red Eye.Blue Eye.Brown Eye.Green\n1          1          0          0        0        0         1         0\n2          0          0          1        0        0         1         0\n3          0          0          0        1        0         1         0\n  Eye.Hazel Sex.Female Sex.Male  n Y.No Y.Yes\n1         0          0        1 32    0     1\n2         0          0        1 53    0     1\n3         0          0        1 10    0     1\n```\n:::\n:::\n\n\n### `dummy` package\n\n`dummy` creates dummy variables of all the factors and character vectors in a data frame. It also supports settings in which the user only wants to compute dummies for the categorical values that were present in another data set. This is especially useful in the context of predictive modeling, in which the new (test) data has more or other categories than the training data. [^1]\n\n[^1]: Straight from the `dummy` [help file](https://cran.r-project.org/web/packages/dummy/dummy.pdf)\n\n    \n*Some pros*\n\n+ Works with tibbles\n+ Retains numerical columns as is\n+ Can create based dummy variables for numeric columns too\n+ `p` parameter can select terms in terms of frequency\n+ Can grab only those variables in a separate dataframe\n+ Can create based dummy variables for numeric columns too\n\n*Some cons*\n\n+ Doesn't have a formula interface to specify what `Y` is. Need to manually remove response variable from dataframe\n\n\n::: {.cell hash='2017-09-26-dummy-variables-one-hot-encoding_cache/html/unnamed-chunk-4_2adaaa2132dad0181031362b6b32edae'}\n\n```{.r .cell-code}\nlibrary(dummy)\nhead(dummy(HairEyeColor),3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Hair_Black Hair_Blond Hair_Brown Hair_Red Eye_Blue Eye_Brown Eye_Green\n1          1          0          0        0        0         1         0\n2          0          0          1        0        0         1         0\n3          0          0          0        1        0         1         0\n  Eye_Hazel Sex_Female Sex_Male Y_No Y_Yes\n1         0          0        1    0     1\n2         0          0        1    0     1\n3         0          0        1    0     1\n```\n:::\n:::\n\n\n*Side note:* there's a useful feature to grab all the categories in a factor variable.\n\n\n::: {.cell hash='2017-09-26-dummy-variables-one-hot-encoding_cache/html/unnamed-chunk-5_eb5e51606652bad1212aa74964b908ff'}\n\n```{.r .cell-code}\ncategories(HairEyeColor)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$Hair\n[1] \"Black\" \"Blond\" \"Brown\" \"Red\"  \n\n$Eye\n[1] \"Blue\"  \"Brown\" \"Green\" \"Hazel\"\n\n$Sex\n[1] \"Female\" \"Male\"  \n\n$Y\n[1] \"No\"  \"Yes\"\n```\n:::\n:::\n\n\n### `caret` package\n\nLastly, there's the `caret` package's `dummyVars()`. This follows a different paradigm. First, we create reciepe of sorts, which just creates an object that specifies how the dataframe gets dummy-fied. Then, use the `predict()` to make the actual conversions.\n\n    \n*Some pros*\n\n+ Works on creating full rank & less than full rank matrix post-conversion\n+ Has a feature to keep only the level names in the final dummy columns \n+ Can directly create a sparse matrix\n+ Retains numerical columns as is\n\n*Some cons*\n\n+ `Y` needs a factor\n+ If the cateogical variables aren't factors, you can't use the `sep=' '` feature\n\n\n::: {.cell hash='2017-09-26-dummy-variables-one-hot-encoding_cache/html/unnamed-chunk-6_4539745b9471e9be5f5143b4790acca4'}\n\n```{.r .cell-code}\nlibrary(caret)\nHairEyeColor$Hair <- as.factor(HairEyeColor$Hair)\nHairEyeColor$Eye <- as.factor(HairEyeColor$Eye)\nHairEyeColor$Sex <- as.factor(HairEyeColor$Sex)\ndV <- dummyVars(formula = Y~.,data = HairEyeColor)\ndV\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDummy Variable Object\n\nFormula: Y ~ .\n5 variables, 4 factors\nVariables and levels will be separated by '.'\nA less than full rank encoding is used\n```\n:::\n:::\n\n::: {.cell hash='2017-09-26-dummy-variables-one-hot-encoding_cache/html/unnamed-chunk-7_a96121ec20926be223e298d4743b48a4'}\n\n```{.r .cell-code}\nhead(predict(object = dV, newdata = HairEyeColor),3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Hair.Black Hair.Blond Hair.Brown Hair.Red Eye.Blue Eye.Brown Eye.Green\n1          1          0          0        0        0         1         0\n2          0          0          1        0        0         1         0\n3          0          0          0        1        0         1         0\n  Eye.Hazel Sex.Female Sex.Male  n\n1         0          0        1 32\n2         0          0        1 53\n3         0          0        1 10\n```\n:::\n:::\n\n\n## Performance comparison\n\nI've run these benchmarks on my Macbook Pro with these specs:\n\n*  Processor Name:\tIntel Core i5\n*  Processor Speed:\t2.4 GHz\n*  Number of Processors:\t1\n*  Total Number of Cores:\t2\n*  L2 Cache (per Core):\t256 KB\n*  L3 Cache:\t3 MB\n*  Memory:\t8 GB\n\n\n### Smaller datasets\n\nThe first dataset used is the `HairEyeColor`. 32 rows, 1 numeric var, 3 categorical var. All the resulting dataframes are as similar as possible... they all retain the `Y` variable at the end.\n\n\n::: {.cell hash='2017-09-26-dummy-variables-one-hot-encoding_cache/html/unnamed-chunk-8_aba05315a5eb427bf714ccc351e7dd9d'}\n\n```{.r .cell-code}\nlibrary(microbenchmark)\nHairEyeColor_df <- as.data.frame(HairEyeColor)\n\nstats_fn <- function(D){\n    stats::model.matrix(Y~.-1,D) %>% \n        cbind(D$Y)\n}\n\ndummies_fn <- function(D){\n    dummies::dummy.data.frame(D[,-5]) %>% \n        cbind(D$Y)\n}\n\ndummy_fn <- function(D){\n    dummy::dummy(D[,-5]) %>% \n        cbind(D$Y)\n}\n\ncaret_fn <- function(D){\n    dV <- caret::dummyVars(formula = Y~.,data = D)\n    predict(object = dV, newdata = D) %>% \n        cbind(D$Y)\n    }\n\nmicrobenchmark::microbenchmark(\n    stats = stats_fn(D = HairEyeColor),\n    dummies = dummies_fn(D = HairEyeColor_df),\n    dummy = dummy_fn(D = HairEyeColor),\n    caret = caret_fn(D = HairEyeColor),\n    times = 1000L,\n    control = list(order = 'block'),\n    unit = 's'\n    ) -> benchmarks\n\nautoplot(benchmarks)\n```\n\n::: {.cell-output-display}\n![](2017-09-26-dummy-variables-one-hot-encoding_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nThe results speak for themself. The `stats` is clearly the fastest with `dummies` and `caret` being a more distant 2nd & 3rd.\n\n### Large datasets\n\nTo leverage a large dataset for this analysis, I'm using the [Accident & Traffic Flow](https://www.kaggle.com/daveianhickey/2000-16-traffic-flow-england-scotland-wales/data) dataset, which is fairly big - 570,011 rows and 33 columns. I've narrowed down to 7 categorical variables to test the packages, and I've created a fake response variable as well.\n\n\n::: {.cell hash='2017-09-26-dummy-variables-one-hot-encoding_cache/html/unnamed-chunk-9_9e26e0b1cca373f7c9d2ee949e4b6c60'}\n\n```{.r .cell-code}\ndata <- read_csv('~/github/github.com/blog-large-data/accidents_2005_to_2007.csv',progress = F)\ndata %<>%\n    transmute(\n        Day_of_Week = as.factor(Day_of_Week),\n        Road_Type = Road_Type %>% stringr::str_replace_all('[()/ ]','.') %>% as.factor,\n        Weather = Weather_Conditions %>% stringr::str_replace_all('[()/ ]','.') %>% as.factor,\n        RoadSurface = Road_Surface_Conditions %>% stringr::str_replace_all('[()/ ]','.') %>% as.factor,\n        PedHC =  `Pedestrian_Crossing-Human_Control` %>% stringr::str_replace_all('[()/ ]','.') %>% as.factor,\n        PedPF =  `Pedestrian_Crossing-Physical_Facilities` %>% stringr::str_replace_all('[()/ ]','.') %>% as.factor,\n        Year =  as.factor(Year)\n    ) %>% \n    mutate(\n        Y = sample(c(0,1),dim(data)[1],replace = T) %>% factor(levels = c(0,1),labels = c('No','Yes'))\n    )\ndim(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 570011      8\n```\n:::\n:::\n\n\nIn total, there will be 39 dummy variable columns created for these 7 factor variables, as we can see here:\n\n::: {.cell hash='2017-09-26-dummy-variables-one-hot-encoding_cache/html/unnamed-chunk-10_838b03d3fe16fcd598a131bb271f4f9f'}\n\n```{.r .cell-code}\nmap_int(data,~length(levels(.x)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDay_of_Week   Road_Type     Weather RoadSurface       PedHC       PedPF \n          7           6           9           5           3           6 \n       Year           Y \n          3           2 \n```\n:::\n:::\n\n\nNow for the benchmarks:\n\n::: {.cell hash='2017-09-26-dummy-variables-one-hot-encoding_cache/html/unnamed-chunk-11_8e5ceaa80fc166d4b8fdb68dc2705ab0'}\n\n```{.r .cell-code}\ndata_df <- as.data.frame(data)\nstats_fn <- function(D){\n    stats::model.matrix(Y~.-1,D) %>% \n        cbind(D$Y)\n}\n\ndummies_fn <- function(D){\n    dummies::dummy.data.frame(D[,-8]) %>% \n        cbind(D$Y)\n}\n\ndummy_fn <- function(D){\n    dummy::dummy(D[,-8]) %>% \n        cbind(D$Y)\n}\n\ncaret_fn <- function(D){\n    dV <- caret::dummyVars(formula = Y~.,data = D)\n    predict(object = dV, newdata = D) %>% \n        cbind(D$Y)\n    }\n\nmicrobenchmark::microbenchmark(\n    stats = stats_fn(D = data),\n    dummies = dummies_fn(D = data_df),\n    dummy = dummy_fn(D = data),\n    caret = caret_fn(D = data),\n    times = 30L,\n    control = list(order = 'block')\n    ) -> benchmarks\n\nautoplot(benchmarks)\n```\n\n::: {.cell-output-display}\n![](2017-09-26-dummy-variables-one-hot-encoding_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nJust like before, `stats` is clerly the fastest.\n\n## Conclusion\n\n+ Stick to `stats::model.matrix()`. It works with tibbles, it's fast, and it takes a formula.\n+ If you like the `caret` package and it's interface, it's the 2nd best choice. \n+ `dummy` or `dummies` doesn't seem to offer any advantages to these packages.\n\n## Qs\n\n+ Are there other packages you recommend for dummy variable creation? If yes, please let me know in the comments.\n+ Could you run the bench marks on more powerful machines and larger datasets, and share your results? I'd like to append them here.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}