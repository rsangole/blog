{
  "hash": "2752f6293573f1ce44ed311eb7a0ff54",
  "result": {
    "markdown": "---\ntitle: Performance Benchmarking for Date-Time conversions\ndate: '2018-04-12'\ncategories:\n  - Benchmarking\n  - Programming Practices\nimage: clocks.jpg\n---\n\n\n\n\n## Motivation\n\nOnce more, there's was an opportunity at work to optimize code and reduce run-time. The last time was for [dummy-variable creation](http://rsangole.netlify.com/post/dummy-variables-one-hot-encoding/). Upon querying  large data from our hive tables, the returned dataframe contains values of class `character`. Thus, everything has to be first type converted before any processing can be done.\n\nThe most time consuming of these has been `character` to `date-time` conversion for which I traditionally used `base::as.POSIXct`.\n\nUpon searching for some options myself, some help from Twitter, I've compared the performance of 6 functions on a 1e7 size character vector.\n\n![](Henning_on_Twitter.png){width=450px}\n\n## Performance comparison\n\nI've run these benchmarks on my Macbook Pro:\n\n*  Processor Name:\tIntel Core i5\n*  Processor Speed:\t2.4 GHz\n*  Number of Processors:\t1\n*  Total Number of Cores:\t2\n*  L2 Cache (per Core):\t256 KB\n*  L3 Cache:\t3 MB\n*  Memory:\t8 GB\n\n## Packages compared\n\n* `base::strptime`\n* `base::as.POSIXct`\n* `lubridate::parse_date_time`\n* `lubridate::parse_date_time2` [fast C parser]\n* `lubridate::fast_strptime` [fast C parser]\n* `fasttime::fastPOSIXct` [fast C parser]\n\n\n::: {.cell hash='2018-04-12-performance-benchmarking-for-date-time-conversions_cache/html/unnamed-chunk-1_c1e71945d4f8e79a5e6097c32dedd438'}\n\n```{.r .cell-code}\ntvec <- rep(as.character(Sys.time()+runif(1,-1e9,1e9)),1e7)\n\nstrp_fn <- function(tvec) strptime(tvec, format = '%Y-%m-%d %H:%M:%S', tz = 'UTC')\nPOSIX_fn <- function(tvec) as.POSIXct(tvec, format = '%Y-%m-%d %H:%M:%S', tz = 'UTC')\npdt_fn <- function(tvec) lubridate::parse_date_time(tvec, orders = 'Ymd H M S', tz = 'UTC')\npdt2_fn <- function(tvec) lubridate::parse_date_time2(tvec, orders = 'Ymd H M S', tz = 'UTC')\nfaststrp_fn <- function(tvec) lubridate::fast_strptime(tvec, format = '%Y-%m-%d %H:%M:%OS', tz = 'UTC')\nfasttime_fn <- function(tvec) fasttime::fastPOSIXct(x = tvec, tz = 'UTC', required.components = 6)\n\nbenchmarks <- microbenchmark::microbenchmark(\n    strptime = strp_fn(tvec),          asPOSIXct = POSIX_fn(tvec),\n    parse_date_time = pdt_fn(tvec),    parse_date_time2 = pdt2_fn(tvec),\n    fast_strptime = faststrp_fn(tvec), fastPOSIXct = fasttime_fn(tvec),\n    times = 30L, unit = 's')\n\nggplot2::autoplot(benchmarks, log = F)\nprint(benchmarks) ; print(benchmarks, unit = 'relative')\n```\n:::\n\n\n## Results\n\n\n::: {.cell hash='2018-04-12-performance-benchmarking-for-date-time-conversions_cache/html/unnamed-chunk-2_bfaf3caa7fe79b90c6c67dd68fd6d329'}\n::: {.cell-output-display}\n![](2018-04-12-performance-benchmarking-for-date-time-conversions_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\nThe results are quite amazing. `fastPOSIXct` wins by a massive margin. `as.POSIXct` is 10x slower than `fastPOSIXct` and has a wider spread too.\n\n\n::: {.cell hash='2018-04-12-performance-benchmarking-for-date-time-conversions_cache/html/unnamed-chunk-3_2c7bc6c6610ca420f33e7267275e7777'}\n::: {.cell-output .cell-output-stdout}\n```\nUnit: relative\n             expr       min        lq     mean    median       uq      max\n         strptime  7.140213  6.995050 6.587170  6.931937 6.243467 5.545282\n        asPOSIXct 10.888603 10.668598 9.886067 10.338859 9.127702 8.170841\n  parse_date_time  3.658794  3.700901 3.607782  3.840411 3.530341 3.136295\n parse_date_time2  1.973176  1.957485 1.864200  1.924281 1.753341 1.701600\n    fast_strptime  1.795452  1.753926 1.717556  1.772935 1.605809 1.588742\n      fastPOSIXct  1.000000  1.000000 1.000000  1.000000 1.000000 1.000000\n neval\n    30\n    30\n    30\n    30\n    30\n    30\n```\n:::\n:::\n\n\nIf you run these bench marks on more powerful machines or larger datasets, share your results too. It'll be interesting to see if this result scales.\n\nThanks [Henning](https://twitter.com/henningsway) for the winning package suggestion! I owe you some beer!",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}