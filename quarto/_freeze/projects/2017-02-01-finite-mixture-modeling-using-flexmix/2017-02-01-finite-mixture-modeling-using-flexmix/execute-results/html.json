{
  "hash": "79ab35a0f84bdf94e79a28a2103ad921",
  "result": {
    "markdown": "---\ntitle: Finite Mixture Modeling using Flexmix\ndate: '2017-02-01'\ncategories:\n  - Flexmix\n  - Mixture Modeling\n---\n\n\n\n\nThis page replicates the codes written by Grun & Leish (2007) in ['FlexMix: An R package for finite mixture modelling', University of Wollongong, Australia.](http://ro.uow.edu.au/cgi/viewcontent.cgi?article=3410&context=commpapers) My intent here was to learn the flexmix package by replicating the results by the authors.\n\n# Model Based Clustering\n\nThe model based clustering on the whiskey dataset. The whiskey dataset is from the Simmons Study of Media and Markets (Fall 1997), and contains the incidence matrix for scotch brands in households who reported consuming scotch for period of 1 year. The dataset is taken from [Edwards and Allenby (2003).](https://www.researchgate.net/profile/Greg_Allenby/publication/247837327_Multivariate_Analysis_of_Multiple_Response_Data/links/547480910cf2778985abe334.pdf)\n\nLoad the necessary packges first: `tidyverse` and `flexmix`.\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-1_b100be6d1d1b47ad686defd97d76fdf1'}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(flexmix)\nlibrary(ggplot2)\nlibrary(tidyr)\n```\n:::\n\n\n## Quick EDA\nQuick look at the data itself. The dataframe consists of 2 elements - frequency (numeric vector), and the incidence matrix. There are total of 484 observations.\n\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-2_530cf31d5f5b303edd260b9b099d9fd7'}\n\n```{.r .cell-code}\ndata(\"whiskey\")\ndf <- whiskey\nset.seed(1802)\nstr(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t484 obs. of  2 variables:\n $ Freq     : int  1 1 10 14 10 23 9 8 1 12 ...\n $ Incidence: num [1:484, 1:21] 1 0 0 0 0 0 0 0 0 0 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : chr [1:484] \"1\" \"2\" \"3\" \"4\" ...\n  .. ..$ : chr [1:21] \"Singleton\" \"Knockando\" \"White Horse\" \"Scoresby Rare\" ...\n```\n:::\n:::\n\n\nThe column names of the `df$Incidence` matrix are the brands of whiskey.\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-3_f0ae8c706d4da4b5e6e94c603ee7f7be'}\n\n```{.r .cell-code}\ncolnames(df$Incidence)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"Singleton\"                  \"Knockando\"                 \n [3] \"White Horse\"                \"Scoresby Rare\"             \n [5] \"Ushers\"                     \"Macallan\"                  \n [7] \"Grant's\"                    \"Passport\"                  \n [9] \"Black & White\"              \"Clan MacGregor\"            \n[11] \"Ballantine\"                 \"Pinch (Haig)\"              \n[13] \"Other brands\"               \"Cutty Sark\"                \n[15] \"Glenfiddich\"                \"Glenlivet\"                 \n[17] \"J&B\"                        \"Dewar's White Label\"       \n[19] \"Johnnie Walker Black Label\" \"Johnnie Walker Red Label\"  \n[21] \"Chivas Regal\"              \n```\n:::\n:::\n\n\nThe incidence matrix shows a relationship between two classes of variables - in this case: freqencies of the brand of whiskey in the past year, and the brand of whiskey itself. Quick look at a portion of the matrix:\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-4_73b437e13d81d5bea9c5764a9802b200'}\n\n```{.r .cell-code}\ndf$Incidence[sample(x = 1:484,size = 10),sample(1:21,3)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    Macallan Cutty Sark Black & White\n119        0          1             0\n8          0          0             0\n245        0          0             1\n347        0          0             0\n26         0          1             0\n221        1          0             0\n1          0          0             0\n178        1          0             0\n411        0          0             0\n224        0          1             0\n```\n:::\n:::\n\n\nThe popularity of the whiskeys can be seen here. Chivas Regal seems to be a favourite, which puts my personal preference in line with a larger population :)\n\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-5_8b1e5f271d2b814af1bbf4476480f11b'}\n\n```{.r .cell-code}\nc <- colSums(df$Incidence)\nd1 <- data.frame(Brand=names(c),counts=c,row.names = NULL)\nd1 <- d1 %>% left_join(whiskey_brands) %>% arrange(-counts)\nggplot(d1,aes(reorder(Brand,counts),counts,fill=Type))+geom_bar(stat='identity')+coord_flip()+labs(y='Counts',x='Whiskey Brand')\n```\n\n::: {.cell-output-display}\n![](2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n## Model building\n\nThe first model in the paper is a stepped Flexmix model, specific for binary variables using the `FLXMcvbinary()` model. Since the objective is to cluster the model based on the Incidence counts and Frequencies, the formula used is `Incidence ~ 1`. The frequencies themselves are input as `weights` in the formula.\n\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-6_7e3149dcbba8df6eb41b55d87fe6b067'}\n\n```{.r .cell-code}\nwh_mix <- stepFlexmix(Incidence ~ 1,\n                      weights = ~ Freq, \n                      data = df,\n                      model = FLXMCmvbinary(truncated = TRUE),\n                      control = list(minprior = 0.005),\n                      k=1:7,\n                      nrep=5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1 : * * * * *\n2 : * * * * *\n3 : * * * * *\n4 : * * * * *\n5 : * * * * *\n6 : * * * * *\n7 : * * * * *\n```\n:::\n\n```{.r .cell-code}\nsummary(wh_mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Length       Class        Mode \n          1 stepFlexmix          S4 \n```\n:::\n:::\n\n\nA top model can be selecting using BIC or AIC criteria. The BIC criteria selects a model with 5 clusters.\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-7_c1bcb91ce327c7ee21eeb42c82336967'}\n\n```{.r .cell-code}\nplot(BIC(wh_mix),type='b',ylab='BIC')\npoints(x = which.min(BIC(wh_mix)),min(BIC(wh_mix)),col='red',pch=20)\n```\n\n::: {.cell-output-display}\n![](2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nwh_best <- getModel(wh_mix,'BIC')\nprint(wh_best)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nstepFlexmix(Incidence ~ 1, weights = ~Freq, data = df, model = FLXMCmvbinary(truncated = TRUE), \n    control = list(minprior = 0.005), k = 5, nrep = 5)\n\nCluster sizes:\n  1   2   3   4   5 \n 24 262 794 161 977 \n\nconvergence after 127 iterations\n```\n:::\n:::\n\n\nThe proportions of the observations in each cluster are shown here:\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-8_f40dc2587dcc188a84279b5eab4d12e2'}\n\n```{.r .cell-code}\nround(prop.table(table(wh_best@cluster)),2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   1    2    3    4    5 \n0.04 0.25 0.19 0.23 0.29 \n```\n:::\n:::\n\n\nThe parameter estimates plotted for model with k=5 is shown below graphically. Component 3 (4% of households) contain the largest number of different brands. Component 1 (25% of households) seen to prefer single malt whiskeys. Component 4 (23% of households) are across the board with Brands, but perhaps show lesser of an interest in single malts, just like Component 5 (29% of the households). \n\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-9_34c795c429e24f3ffedeeffa4cc2e4fe'}\n\n```{.r .cell-code}\n# wh_best.prior <- prior(wh_best)\nwh_best.param <- parameters(wh_best)\nwh_best.param <- data.frame(Brand=stringr::str_replace(rownames(wh_best.param),pattern = 'center.',replacement = ''),\nwh_best.param,row.names = NULL) \nwh_best.param <- wh_best.param %>% gather(Components,Value,Comp.1:Comp.5)\nwh_best.param <- wh_best.param %>% left_join(y = whiskey_brands,by = 'Brand')\nggplot(wh_best.param,aes(y=Value,x=Brand,fill=Type))+\n    geom_bar(stat='identity')+\n    coord_flip()+\n    facet_grid(.~Components)\n```\n\n::: {.cell-output-display}\n![](2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-9-1.png){width=768}\n:::\n:::\n\n\n# Mixtures of Regressions\n\nThe next example in the paper is the patent data in Wang et al. (1998). The help file `?patent` notes that the data consists of the number of patents, R&D spending and sales in millions of dollar for 70 pharmaceutical and biomedical companies in 1976, taken from the National Bureau of Economic Research R&D Masterfile. \n\n## Quick EDA\n\nThe dependant variable here is `Patents`. Independant variable is `lgRD` which is the log of R&D spending. The objective in this exercise is to try and find how many may clusters exist within this bi-variate dataset. When I started this exercise, it seemed quite moot to me, since visually, I couldn't really tell any distict clusters. But, the results show otherwise.\n\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-10_f281a77c04245ee8124b30f0ab5d69de'}\n\n```{.r .cell-code}\ndata(\"patent\")\ndf_patent <- tbl_df(patent)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `tbl_df()` was deprecated in dplyr 1.0.0.\nPlease use `tibble::as_tibble()` instead.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n```\n:::\n\n```{.r .cell-code}\ndf_patent\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 70 × 4\n   Company                                    Patents    RDS   lgRD\n   <chr>                                        <int>  <dbl>  <dbl>\n 1 \"ABBOTT LABORATORIES                     \"      42 0.0549  4.09 \n 2 \"AFFILIATED HOSPITAL PRDS                \"       1 0.0032 -2.08 \n 3 \"ALBERTO-CULVER CO                       \"       3 0.0078  0.119\n 4 \"ALCON LABORATORIES                      \"       2 0.0803  1.88 \n 5 \"ALLERGAN PHARMACEUTICALS INC            \"       3 0.0686  1.10 \n 6 \"ALZA CORP-CL A                          \"      40 3.33    2.08 \n 7 \"AMERICAN HOME PRODUCTS CORP             \"      60 0.0243  4.10 \n 8 \"AMERICAN HOSPITAL SUPPLY                \"      30 0.0128  2.83 \n 9 \"AMERICAN STERILIZER CO                  \"       7 0.0252  1.39 \n10 \"AVON PRODUCTS                           \"       3 0.0094  2.60 \n# … with 60 more rows\n```\n:::\n\n```{.r .cell-code}\nplot(Patents~lgRD,df_patent)\n```\n\n::: {.cell-output-display}\n![](2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n## Model Building\n\nThe paper mentions that Wang et al. (1998) chose a finite mixture of three Poisson regression models to represent the data. The `FLXMRglm()` is used for the Poisson model with a concomitant variable modeled using `FLXPmultinom()`.\n\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-11_f676748b445f32d26bd04674149025da'}\n\n```{.r .cell-code}\npat_mix <- flexmix(Patents ~ lgRD, k = 3, data = df_patent, model = FLXMRglm(family = \"poisson\"), concomitant = FLXPmultinom(~RDS))\npat_mix\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nflexmix(formula = Patents ~ lgRD, data = df_patent, k = 3, model = FLXMRglm(family = \"poisson\"), \n    concomitant = FLXPmultinom(~RDS))\n\nCluster sizes:\n 1  2  3 \n12 13 45 \n\nconvergence after 33 iterations\n```\n:::\n:::\n\n\nThe clusters obtained from the analysis are given by a `cluster()` function.\n\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-12_a1fe287216974219cb51cec143debcb3'}\n\n```{.r .cell-code}\nclusters(pat_mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 1 3 3 1 3 2 3 3 3 1 3 2 3 3 1 3 1 2 3 3 1 1 2 3 2 3 3 3 3 1 3 3 3 3 2 3 3 1\n[39] 2 3 3 3 3 2 3 3 1 3 2 3 3 1 3 3 3 3 3 1 3 3 3 3 2 3 2 2 3 3 2 3\n```\n:::\n:::\n\n\n## Results\n\nThe data is replotted but with colors for the clusters and additional splines. As we can see, the model beautifully models three lines through three clusters in the data.\n\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-13_82cc303ef6bd59ba1de5b376d44c94ce'}\n\n```{.r .cell-code}\nComponents <- factor(clusters(pat_mix))\nxyplot(Patents~lgRD,groups = Components,df_patent,type=c('p','spline'))\n```\n\n::: {.cell-output-display}\n![](2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n## Further investigation\n\nThe `flexmix` package has a function to plot rootograms of the posterior probabilities of observations. Observations where the a-posteriori probability is large for component #1 and #3 are indicated. As we can see where component #1 has highest probabilities indicated in the 1st bucket, they are lowest in #2 and #3 buckets.\n\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-14_1b2ed1c1a21b574785dd9ed5ad31afd3'}\n\n```{.r .cell-code}\nplot(pat_mix,mark=1)\n```\n\n::: {.cell-output-display}\n![](2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(pat_mix,mark=3)\n```\n\n::: {.cell-output-display}\n![](2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-14-2.png){width=672}\n:::\n:::\n\n\nA summary of the mixture model results show the estimated priors, number of observations within each cluster (size), number of observations with p>10^-4 (post>0), and a ratio of the two. The rations of 0.58, 0.42 and 0.18 indicate big overlaps of the clusters. This can also be observed by the large portion of values in the mid-section of the rootogram above. \n\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-15_bc8fdab72a7bcd44275a51b4a82e565e'}\n\n```{.r .cell-code}\nsummary(pat_mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nflexmix(formula = Patents ~ lgRD, data = df_patent, k = 3, model = FLXMRglm(family = \"poisson\"), \n    concomitant = FLXPmultinom(~RDS))\n\n       prior size post>0 ratio\nComp.1 0.201   12     48 0.250\nComp.2 0.184   13     47 0.277\nComp.3 0.615   45     63 0.714\n\n'log Lik.' -197.6752 (df=10)\nAIC: 415.3505   BIC: 437.8354 \n```\n:::\n:::\n\n\nTests of significance of the coefficients are obtained by the `refit()`. In each cluster the intercept and lgRD are both statistically significant at the 0.05 level. The black bars in the plot are 95% CI over the point estimates.\n\n\n::: {.cell hash='2017-02-01-finite-mixture-modeling-using-flexmix_cache/html/unnamed-chunk-16_c48331d3940704371c4028a1b93b2cbe'}\n\n```{.r .cell-code}\nrm <- refit(pat_mix)\nsummary(rm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$Comp.1\n            Estimate Std. Error z value  Pr(>|z|)    \n(Intercept) -2.63638    0.62672 -4.2067 2.592e-05 ***\nlgRD         1.58644    0.13393 11.8454 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n$Comp.2\n            Estimate Std. Error z value  Pr(>|z|)    \n(Intercept) 1.962173   0.176485  11.118 < 2.2e-16 ***\nlgRD        0.671908   0.045639  14.722 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n$Comp.3\n            Estimate Std. Error z value  Pr(>|z|)    \n(Intercept) 0.508194   0.160927  3.1579  0.001589 ** \nlgRD        0.879702   0.040249 21.8564 < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\nplot(rm,bycluster=F)\n```\n\n::: {.cell-output-display}\n![](2017-02-01-finite-mixture-modeling-using-flexmix_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nThe authors note that \"estimates vary between all components even though the co- efficients for lgRD are similar for the first and third component\".\n\n# Notes\n\n* For both the models, although I'm using the exact datasets and seed values, I observe different values for proportions in each cluster (for model #1) as well as P values for significance etc (for model #2). This could be due to some changes in the underlying flexmix codes since 2007.\n\n# References\n\n* http://ro.uow.edu.au/cgi/viewcontent.cgi?article=3410&context=commpapers\n* http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.491.3320&rep=rep1&type=pdf\n* https://cran.r-project.org/web/packages/flexmix/index.html\n* https://cran.r-project.org/web/packages/flexmix/vignettes/mixture-regressions.pdf\n* https://cran.r-project.org/web/packages/flexmix/vignettes/flexmix-intro.pdf\n* https://cran.r-project.org/web/packages/flexmix/vignettes/bootstrapping.pdf\n* [https://www.researchgate.net/profile/Greg_Allenby/.../...e334.pdf](https://www.researchgate.net/profile/Greg_Allenby/publication/247837327_Multivariate_Analysis_of_Multiple_Response_Data/links/547480910cf2778985abe334.pdf)\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}