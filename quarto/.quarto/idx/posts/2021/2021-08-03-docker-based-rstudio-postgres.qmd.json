{"title":"Docker based RStudio & PostgreSQL","markdown":{"yaml":{"title":"Docker based RStudio & PostgreSQL","author":"Rahul","date":"2021-08-07","slug":"docker-based-rstudio-postgres","categories":["docker-series"],"tags":["docker","postgres"],"output":{"blogdown::html_page":{"toc":true,"toc_depth":1}}},"headingText":"Background","containsRefs":false,"markdown":"\n\n*This is part one of the two part post related to Docker, PostgreSQL databases and Anomaly data-sets.*\n\n\nIn recent LinkedIn posts ([original](https://www.linkedin.com/posts/rahulsangole_rstats-datascience-analytics-activity-6824183826877698048-0ImA) and [Rami](https://github.com/RamiKrispin)'s [repost](https://www.linkedin.com/posts/rami-krispin_anomalydetection-data-timeseries-activity-6825126331672612864-MEks)) and [tweet](https://twitter.com/rsangole/status/1418418477329620993), I asked the internet for their favorite datasets for anomaly detection problems, particularly in the time-series domain. I got lots of responses, and now have a massive amount of data to play with, thank you folks who responded.\n\nTo play with these data, I wanted a better solution than keeping data as CSV files, `qs` objects, or in R Packages. I wanted a database to store the raw input data, my processed data and algorithm results. While I've setup databases in the past the traditional way, this time I wanted the entire codebase to be portable & reproducible.\n\nAs a result, I setup everything using Docker and it works seemlessly. If you'd like to learn how to do so, follow along my next posts:\n\n-   Part I - (this post) Will teach you how to setup a simple reproducible Docker based workflow for a personal PostgreSQL Database + RStudio for code development\n-   Part II - (next post) Will be the ETL pipelines for anomaly data\n\n# Why should you read this?\n\nAt the end of this tutorial, you'll be able to rapidly setup a Docker based personal[^1] PostgreSQL database. You will learn how to quickly deploy PostgreSQL & RStudio using `docker-compose`. You will be able to access the database in R and begin development immediately. And most importantly, the whole process will be fully reproducible as you inherit the benefits of setup scripts and Docker.\n\n[^1]: I harp on 'personal' given I'm not setting up appropriate roles, auth etc needed in a work environment. But, it's good enough for my personal use.\n\n*This tutorial assumes you're familiar with Docker and RStudio in a Docker environment. If you're not, I recommend reading [Reproducible Work in R](https://rsangole.netlify.app/post/2020/10/10/reproducible-work-in-r/) first.*\n\n# Overview\n\nYou will be launching two Docker images:\n\n1.  A PostgreSQL image. I choose [`postgres:13.3`](https://hub.docker.com/_/postgres/)\n2.  An RStudio image. I choose [`hatmatrix/blog:base`](https://hub.docker.com/r/hatmatrix/blog/tags?page=1&ordering=last_updated) [^2]\n\n[^2]: This is my own image based off of [`rocker/rstudio`](https://hub.docker.com/r/rocker/rstudio)\n\nTo permanently store your data beyond the life of the containers, you will mount two volumes, one for each container. I chose:\n\n1.  For PostgreSQL: `$HOME/docker/volumes/postgres`\n2.  For R Projects: `$HOME/github`\n\n![](/post/docker-compose.png)[^3]\n\n[^3]: \n<div>DB icon by <a href=\"https://www.flaticon.com/authors/pixel-perfect\" title=\"Pixel perfect\">Pixel perfect</a></div>\n<div>Folder icon by <a href=\"https://www.flaticon.com/authors/icongeek26\" title=\"Icongeek26\">Icongeek26</a></div>\n<div>RAM icon by <a href=\"https://www.freepik.com\" title=\"Freepik\">Freepik</a></div>\n<div>Storage icon by <a href=\"https://smashicons.com/\" title=\"Smashicons\">Smashicons</a></div>\n\nNone of these paths, except for the in-container PostgreSQL are special; you can customize the others to your liking. By default, `postgres:13.3` expects the database to be at `/var/lib/postgresql/data`. If you choose another database, modify this accordingly.\n\nI use `docker-compose` to launch both PostgreSQL and RStudio services together. It's convenient while also ensuring the PostgreSQL service runs first followed by RStudio. It's easy to start or stop all the services using just a few commands.\n\n# First Time Setup\n\nYou need to run these steps the first time you're setting up the PostgreSQL database. I've stored these steps in [`00-postgres-init.sh`.](https://github.com/rsangole/postgres/blob/master/00-postgres-init.sh)\n\n### 1 - Directory Setup\n\nYou need a local directory to store the PostgreSQL database in. Lines 3-10 take care of this for you.\n\n``` {.sh}\n# create directory if does not exist\nif [ -d \"$HOME/docker/volumes/postgres\" ] \nthen\n    echo \"Directory $HOME/docker/volumes/postgres exists.\" \nelse\n    echo \"Error: Directory $HOME/docker/volumes/postgres does not exists.\"\n    mkdir -p $HOME/docker/volumes/postgres\nfi\n```\n\n### 2 - PostgreSQL Setup\n\nNow it's time to setup the database. You need two steps at a minimum to get started:\n\n1.  A new 'role' (akin to a login) with rights to create new databases.\n2.  At least one database to work in. In my script, I'm making two: `work` and `anomaly`.\n\nTo manipulate the database, you need a PostgreSQL server running to process the `psql` commands. You'll launch one using `docker run`. You need the correct volume mounted using `-v`. Next, we create the role and databases by piping `psql` commands into `docker exec`. Then, we stop the container.\n\n``` {.sh}\n# launch the postgres image called 'post_setup',\n# attach it to the local volume\ndocker run --rm --name post_setup \\\n  -e POSTGRES_USER=postgres \\\n  -e POSTGRES_PASSWORD=docker \\\n  -d \\\n  -p 5432:5432 \\\n  -v $HOME/docker/volumes/postgres:/var/lib/postgresql/data \\\n  postgres:13.3\n\n# create a new role, and two databases\necho \"CREATE ROLE rahul WITH PASSWORD 'pass' CREATEDB LOGIN;\nCREATE DATABASE work; CREATE DATABASE anomaly;\" | \\\n docker exec -i post_setup \\\n psql -U postgres\n\n# stop the docker container\ndocker stop post_setup\n```\n\nIn summary, now I have a PostgresSQL database:\n\n-   stored at `$HOME/docker/volumes/postgres`\n-   with a new role `rahul` and password `pass`\n-   with 2 databases: `work` and `anomaly`\n\n# Daily Workflow\n\n### tldr: How do you get going?\n\n1.  Store [`docker-compose.yml`](https://github.com/rsangole/postgres/blob/master/docker-compose.yml) in a local directory\n2.  Modify it if you've changed my chosen images/directories\n3.  In shell, run `docker-compose up -d`\n\n*protip*: to launch a browser (firefox for me) directly into RStudio as well, run this command in the directory where you have `docker-compose.yml`:\n\n``` {.sh}\ndocker-compose up -d; firefox localhost:8787\n```\n\n*pro-protip*: save an alias and generalize the command. The `-f` arg instructs `docker-compose` which file you'd like to use. Now [`engage`](https://www.youtube.com/watch?v=0yBoY1SQA5A) can be run from anywhere in the system.\n\n``` {.sh}\nalias engage='docker-compose \\\n            -f $HOME/github/docker/docker-compose.yml \\\n            up -d; firefox localhost:8787' \n```\n\n### The breakdown\n\nWhat's in [`docker-compose.yml`](https://github.com/rsangole/postgres/blob/master/docker-compose.yml)? We're creating two services, one called `db` and the other `rstudio`.[^4]\n\n[^4]: These are just labels, you can call them what you'd like\n\nLet's look at `db` first. Most of the arguments will look familiar if you're familiar with `docker run` args. What's new here is the `restart: unless-stopped` arg which tells Docker to only start PostgreSQL if it's currently stopped.\n\n``` {.yml}\nversion: \"3.3\"\nservices:\n  db:\n    image: postgres:13.3\n    restart: unless-stopped\n    environment:\n      POSTGRES_DB: \"anomaly\"\n      POSTGRES_USER: \"rahul\"\n      POSTGRES_PASSWORD: \"pass\"\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - type: \"bind\"\n        source: \"$HOME/docker/volumes/postgres\"\n        target: \"/var/lib/postgresql/data\"\n```\n\nThe 2nd service is `rstudio`. Apart from the typical args, the interesting arg here is `depends_on` which tells Docker to only run this image *after* the database is up and running. Fantastic!\n\n``` {.yml}\n  rstudio:\n    image: hatmatrix/blog:base\n    ports:\n      - \"8787:8787\"\n      - \"3838:3838\"\n    environment:\n      DISABLE_AUTH: \"true\"\n    volumes:\n      - type: \"bind\"\n        source: \"$HOME/github\"\n        target: \"/home/rstudio\"\n    depends_on:\n      - \"db\"\n```\n\n## Connecting via R\n\nUse [`postgres.R`](https://github.com/rsangole/postgres/blob/master/postgres.R) to test your connection. Run your `DBI::` commands you would normally, *except* for one key difference.\n\nWhile making the connection, make sure the name of the `host` is the name of the database service you've chosen in `docker-compose.yml`. (Outside docker, you would have typically used `localhost` to connect to a local PostgreSQL server).\n\n``` {.r}\ncon <- DBI::dbConnect(\n  drv = RPostgres::Postgres(),\n  dbname = \"anomaly\",\n  host = \"db\", # this needs to be the name of the postgres service\n               # (line 3 in docker-compose.yml)\n  user = \"rahul\",\n  password = \"pass\",\n  port = 5432\n)\n```\n\nThat's it! You're off to the races now. Use the DB as you normally would using [`{DBI}`](https://dbi.r-dbi.org/).\n\n``` {.r}\ncon %>% DBI::dbListTables()\ncon %>% dplyr::tbl(\"table_name\")\n```\n\n## To Stop Services\n\nYou have two options here:\n\n1.  `docker-compose stop` will stop the services, which you can restart using `docker-compose start`.\n2.  `docker-compose down` will and remove containers as well. Run `docker-compose up` to get going once again.\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":{"blogdown::html_page":{"toc":true,"toc_depth":1}},"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"2021-08-03-docker-based-rstudio-postgres.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.0.38","theme":"simplex","title":"Docker based RStudio & PostgreSQL","author":"Rahul","date":"2021-08-07","slug":"docker-based-rstudio-postgres","categories":["docker-series"],"tags":["docker","postgres"]},"extensions":{"book":{"multiFile":true}}}}}